{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "asgmt9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMe-1JqbNFRc",
        "outputId": "b26fe84c-3416-4fff-b9c9-f4feb9fadbe1"
      },
      "source": [
        "%rm -rf 'EvaLibrary'\n",
        "!git clone https://github.com/nishantb06/EvaLibrary.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EvaLibrary'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 91 (delta 48), reused 7 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (91/91), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHDDZdMaR--x",
        "outputId": "23244785-3a29-4790-b2c1-8c89bbf02857"
      },
      "source": [
        "!pip install albumentations==0.4.6\n",
        "import albumentations \n",
        "from albumentations.pytorch import ToTensorV2\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations==0.4.6\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Collecting imgaug>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 25.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.0)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.6)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65172 sha256=2a4921bbf2bc2e610bc16ec6668734930289b7fa0e07c456cbbc1a27108fbb67\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9UkiMGjNUAz",
        "outputId": "addda2d3-be03-4e56-f287-8324a60790fb"
      },
      "source": [
        "!python /content/EvaLibrary/main_asgmt9.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "170499072it [00:02, 62493052.88it/s]                   \n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Adjusting learning rate of group 0 to 1.0000e-02.\n",
            "Epoch 1\n",
            "  0% 0/98 [00:00<?, ?it/s]/content/EvaLibrary/models/models_Asgmt9.py:118: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n",
            "Loss=1.2555643320083618 Batch_id=97 Train Accuracy=36.89: 100% 98/98 [00:54<00:00,  1.80it/s]\n",
            "\n",
            "Test set: Average loss: 1.4104, Test Accuracy: 4910/10000 (49.10%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0184e-02.\n",
            "Epoch 2\n",
            "Loss=1.0057388544082642 Batch_id=97 Train Accuracy=58.26: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 1.2003, Test Accuracy: 5763/10000 (57.63%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0368e-02.\n",
            "Epoch 3\n",
            "Loss=0.752490758895874 Batch_id=97 Train Accuracy=67.94: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.8346, Test Accuracy: 7063/10000 (70.63%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0552e-02.\n",
            "Epoch 4\n",
            "Loss=0.7057879567146301 Batch_id=97 Train Accuracy=73.63: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.7006, Test Accuracy: 7607/10000 (76.07%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0736e-02.\n",
            "Epoch 5\n",
            "Loss=0.6591010093688965 Batch_id=97 Train Accuracy=77.37: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.5884, Test Accuracy: 7946/10000 (79.46%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.0920e-02.\n",
            "Epoch 6\n",
            "Loss=0.626548171043396 Batch_id=97 Train Accuracy=80.04: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.5044, Test Accuracy: 8240/10000 (82.40%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.1104e-02.\n",
            "Epoch 7\n",
            "Loss=0.5344107747077942 Batch_id=97 Train Accuracy=81.78: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.4653, Test Accuracy: 8396/10000 (83.96%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.1288e-02.\n",
            "Epoch 8\n",
            "Loss=0.4183642566204071 Batch_id=97 Train Accuracy=82.93: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.4923, Test Accuracy: 8276/10000 (82.76%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.1472e-02.\n",
            "Epoch 9\n",
            "Loss=0.4781288504600525 Batch_id=97 Train Accuracy=84.08: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.4122, Test Accuracy: 8611/10000 (86.11%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.1656e-02.\n",
            "Epoch 10\n",
            "Loss=0.44204288721084595 Batch_id=97 Train Accuracy=85.01: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.4707, Test Accuracy: 8419/10000 (84.19%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.1840e-02.\n",
            "Epoch 11\n",
            "Loss=0.34827008843421936 Batch_id=97 Train Accuracy=86.25: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.4862, Test Accuracy: 8350/10000 (83.50%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.2025e-02.\n",
            "Epoch 12\n",
            "Loss=0.35361018776893616 Batch_id=97 Train Accuracy=86.67: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.3621, Test Accuracy: 8771/10000 (87.71%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.2209e-02.\n",
            "Epoch 13\n",
            "Loss=0.361579954624176 Batch_id=97 Train Accuracy=87.59: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.4028, Test Accuracy: 8679/10000 (86.79%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.2393e-02.\n",
            "Epoch 14\n",
            "Loss=0.378420352935791 Batch_id=97 Train Accuracy=88.18: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.3440, Test Accuracy: 8814/10000 (88.14%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.2577e-02.\n",
            "Epoch 15\n",
            "Loss=0.2509846091270447 Batch_id=97 Train Accuracy=88.72: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.3600, Test Accuracy: 8803/10000 (88.03%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.2761e-02.\n",
            "Epoch 16\n",
            "Loss=0.26264244318008423 Batch_id=97 Train Accuracy=89.24: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.3423, Test Accuracy: 8880/10000 (88.80%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.2945e-02.\n",
            "Epoch 17\n",
            "Loss=0.3404100835323334 Batch_id=97 Train Accuracy=89.51: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.3460, Test Accuracy: 8840/10000 (88.40%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.3129e-02.\n",
            "Epoch 18\n",
            "Loss=0.3839370310306549 Batch_id=97 Train Accuracy=90.18: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.3392, Test Accuracy: 8920/10000 (89.20%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.3313e-02.\n",
            "Epoch 19\n",
            "Loss=0.23412171006202698 Batch_id=97 Train Accuracy=90.71: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.3572, Test Accuracy: 8824/10000 (88.24%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.3497e-02.\n",
            "Epoch 20\n",
            "Loss=0.2632388472557068 Batch_id=97 Train Accuracy=91.05: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.3214, Test Accuracy: 8897/10000 (88.97%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.3681e-02.\n",
            "Epoch 21\n",
            "Loss=0.30141395330429077 Batch_id=97 Train Accuracy=91.60: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.3091, Test Accuracy: 8945/10000 (89.45%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.3865e-02.\n",
            "Epoch 22\n",
            "Loss=0.22435858845710754 Batch_id=97 Train Accuracy=91.82: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.3367, Test Accuracy: 8907/10000 (89.07%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.4049e-02.\n",
            "Epoch 23\n",
            "Loss=0.24979761242866516 Batch_id=97 Train Accuracy=91.80: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.2949, Test Accuracy: 9008/10000 (90.08%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.4233e-02.\n",
            "Epoch 24\n",
            "Loss=0.1947489231824875 Batch_id=97 Train Accuracy=92.18: 100% 98/98 [00:54<00:00,  1.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.3296, Test Accuracy: 8912/10000 (89.12%)\n",
            "\n",
            "Adjusting learning rate of group 0 to 1.4417e-02.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4aaroXN19Ek"
      },
      "source": [
        "# import cv2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ4ZoP97N6mX"
      },
      "source": [
        "# !pip install -U grad-cam\n",
        "# !pip install -U ttach"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q4Q0h4ts5oN"
      },
      "source": [
        "# from pytorch_grad_cam import GradCAM"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2DhP7bKxM-s"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}